<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>用于图像分类的MobileNetV3算法 | TL;DR</title><meta name="keywords" content="学习,深度学习,神经网络,图像分类"><meta name="author" content="何佩奇"><meta name="copyright" content="何佩奇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="用于图像分类的MobileNetV3算法 摘要 ​ 卷积神经网络（CNN）是一种深度神经网络，通过多个卷积层提取图像特征，广泛应用于图像分类。随着移动设备处理的图像数据量的不断增加，神经网络在移动终端上的应用越来越广泛。然而，这些网络需要大量的计算和先进的硬件支持，很难适应移动设备。本文论证了MobileNetV3对于移动终端上的实际图像分类任务，可以在效率和准确性之间取得较好的平衡">
<meta property="og:type" content="article">
<meta property="og:title" content="用于图像分类的MobileNetV3算法">
<meta property="og:url" content="https://shunder.github.io/2022/03/04/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84MobileNetV3%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="TL;DR">
<meta property="og:description" content="用于图像分类的MobileNetV3算法 摘要 ​ 卷积神经网络（CNN）是一种深度神经网络，通过多个卷积层提取图像特征，广泛应用于图像分类。随着移动设备处理的图像数据量的不断增加，神经网络在移动终端上的应用越来越广泛。然而，这些网络需要大量的计算和先进的硬件支持，很难适应移动设备。本文论证了MobileNetV3对于移动终端上的实际图像分类任务，可以在效率和准确性之间取得较好的平衡">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304130605359.png">
<meta property="article:published_time" content="2022-03-04T04:54:47.000Z">
<meta property="article:modified_time" content="2022-03-08T12:14:12.540Z">
<meta property="article:author" content="何佩奇">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="图像分类">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304130605359.png"><link rel="shortcut icon" href="/images/favicon.png"><link rel="canonical" href="https://shunder.github.io/2022/03/04/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84MobileNetV3%E7%AE%97%E6%B3%95/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8b6aac7cd70568c4bfa2c26c32ae4269";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-LLZ3MQ70MV"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LLZ3MQ70MV');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '用于图像分类的MobileNetV3算法',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-08 20:14:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/static-butterfly/dist/css/index.min.css"><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="TL;DR" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/avatar.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-dove"></i><span> 小窝</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/album/"><i class="fa-fw fa-solid fa-images"></i><span> 相册</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://movie.douban.com/people/135578395/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">TL;DR</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-dove"></i><span> 小窝</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/album/"><i class="fa-fw fa-solid fa-images"></i><span> 相册</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://movie.douban.com/people/135578395/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">用于图像分类的MobileNetV3算法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-04T04:54:47.000Z" title="发表于 2022-03-04 12:54:47">2022-03-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-08T12:14:12.540Z" title="更新于 2022-03-08 20:14:12">2022-03-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/">知识学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>21分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="用于图像分类的MobileNetV3算法"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/03/04/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84MobileNetV3%E7%AE%97%E6%B3%95/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2022/03/04/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84MobileNetV3%E7%AE%97%E6%B3%95/" itemprop="commentCount"></span></a></span></div></div></div><article class="post-content" id="article-container"><!-- toc -->
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304130605359.png"
alt="image-20220304130605359" /></p>
<h1
id="用于图像分类的mobilenetv3算法">用于图像分类的MobileNetV3算法</h1>
<h2 id="摘要">摘要</h2>
<p>​
卷积神经网络（CNN）是一种深度神经网络，通过多个卷积层提取图像特征，广泛应用于图像分类。随着移动设备处理的图像数据量的不断增加，神经网络在移动终端上的应用越来越广泛。然而，这些网络需要大量的计算和先进的硬件支持，很难适应移动设备。本文论证了MobileNetV3对于移动终端上的实际图像分类任务，可以在效率和准确性之间取得较好的平衡。在我们的实验中，比较了MobileNetV3和其他几种常用的预训练CNN模型在不同图像数据集上的分类性能。选择的数据集都很好地代表了移动设备的应用场景。结果表明，作为一种轻量级的神经网络，与其他大型网络相比，MobileNetV3以有效的方式实现了良好的精度性能。此外，ROC证实了MobileNetV3相对于其他实验模型的优势。并对适用于MobileNetV3的图像数据集的特征提出了一些猜想。</p>
<h4
id="关键词-卷积神经网络图像分类移动设备mobilenetv3">关键词-卷积神经网络；图像分类；移动设备；MobileNetV3</h4>
<span id="more"></span>
<h2 id="i.-绪论">I. 绪论</h2>
<p>​ 卷积神经网络（Convolutional Neural
Network，CNN）由于其在图像分类、分割和其他计算机视觉问题中的扩展应用而受到极大关注。CNN通常由两部分组成：特征提取部分（由卷积层和池化层组成）和分类部分（包含大量堆叠的全连接层）。在第一部分中，卷积层中的核逐步扫描输入图像，将每个核中的权重乘以像素值，并组合总和来创建传递到下一层的新图像。池化层在下采样中起到减少数据数量和节省计算资源的作用。在第二部分中，图像首先通过flatten层转换为一维数组。接下来的全连接层使用这个数组作为输入，并通过应用线形组合和非线性激活函数来产生预测标签。</p>
<p>​
CNN由于其分层提取深层特征的优势，目前被广泛应用与解决现实世界中的问题，比如自动驾驶和医学影像诊断。由于日常场景中的大量任务，将深度学习应用于移动设备上的日常任务变得非常自然。因此，成功地将CNN应用于移动终端是非常重要的。由于移动设备上有限的计算能力，对模型效率和小内存有很高的要求。</p>
<p>​
有许多为不同任务设计的CNN架构。其中，有些常用于图像分类问题，如Inception、AlexNet和VGG16。然而，移动设备中的分类任务不仅要求高精度，而且更设计的是要求低存储成本和高计算效率，这就产生了适用于移动终端的模型。我们选择MobileNetV3作为我们的主要研究对象，它是轻量级的CNN模型，在准确性和效率之间取得了很好的平衡。</p>
<p>​
本文比较了MobileNetV3、AlexNet、Inception和ShuffleNet在不同数据集上的性能，验证了MobileNetV3的高效性和适应性。本文的主要贡献如下：</p>
<ol type="1">
<li><p>Fruits 360，10 Monkey Species和Bird Species
Classification作为移动设备上常见图像数据集的代表，用于训练和评估所选神经网络的性能。</p></li>
<li><p>MobileNetV3、AlexNet、InceptionV3和ShuffleNetV2应用于与移动场景相关的多个图像分类任务。</p></li>
<li><p>采用多个评估指标来分析不同模型在不同数据集上的性能。</p></li>
<li><p>在实验结果的基础上，总结了MobileNetV3在图像分类方面的特点及其在移动设备上的优势。</p></li>
</ol>
<p>​
本文的其余部分组织如下。在第二章中，我们描述了MobileNetV3的主要结构以及实验中其他模型的特点。在第三章中，介绍了数据集，并评估了MobielNetV3和其他模型的性能。实验结果和分析也见第三章。第四章总结了MobileNetV3的特点，并讨论了我们未来的工作。</p>
<h2 id="ii.-模型的架构">II. 模型的架构</h2>
<p>​
近年来，面向移动终端的CNN网络发展迅速。从2017年到2019年，MobileNet的三个版本在架构上不断改进。MobileNetV1是参考传统的VGG架构开发的，同时引入了深度可分离卷积。在此基础上，一年后退出了具有线形瓶颈和反向残差的MobileNetV2。在NAS和NetAdapt网络搜索架构优化的帮助下，MobileNetV3在2019年年中通过删除开销较高的层和使用h-swish非线性函数代替ReLU来改进，同时提高效率和相对准确性。</p>
<p>​
根据事例目标使用资源的高低，将MobileNetV3定义为MobileNetV3-Small和MobileNTV3-Large两种架构复杂度不同的模型。</p>
<h5
id="表一-mobilenetv3-large的规格expand表示示用于从层的输入扩展特征空间的卷积滤波器的数量se指示在该块中是否存在挤压和激励nl表示该块的非线性类型bn表示批标准化">表一
MobileNetv3-Large的规格。#expand表示示用于从层的输入扩展特征空间的卷积滤波器的数量。SE指示在该块中是否存在挤压和激励。NL表示该块的非线性类型。BN表示批标准化。</h5>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304104154029.png"
alt="image-20220304104154029" /></p>
<p>MobileNetV3-Large的完整规格见表I。</p>
<p>根据详细的层规范，模型的整体架构可以如图1所示。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304104726178.png"
alt="image-20220304104726178" /></p>
<h5
id="图1-mobilenetv3架构mobilenetv3-large和mobilenetv3-small的通用架构相同">图1
MobileNetV3架构。MobileNetv3-Large和MobileNetv3-Small的通用架构相同。</h5>
<p>​
MobileNetV3-Small的一般结构与MobileNetV3-Large几乎相同。此外，MobileNetV3-Small缩短了四层，如表II所示。</p>
<h5 id="表ii-mobilenetv3-small规格所有符号与表i相同">表II
MobileNetV3-Small规格。所有符号与表I相同。</h5>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304104824614.png"
alt="image-20220304104824614" /></p>
<h3 id="a.-深度可分离卷积"><em>A. 深度可分离卷积</em></h3>
<p>​
为了提高计算效率，引入了深度可分离卷积。它与传统的卷积非常相似。与每层只有一次卷积计算的传统卷积不同，深度可分离卷积的卷积计算分为两个阶段。在第一阶段中，深度卷积对每个输入通道应用单个卷积滤波器。在第二阶段中，将逐点卷积（卷积）应用于深度卷积的输出的所有通道。总之，深度可分离卷积通过减少计算量来提高计算速度，但会牺牲一些精度。深度可分离卷积是许多高效模型（如MobileNetV1-V3）的核心技术。</p>
<h3 id="b.-线性瓶颈"><em>B. 线性瓶颈</em></h3>
<p>​
为了在不丢失太多信息的情况下从高维空间中提取特征，MobileNetV2提出了线性瓶颈来降低输入的维数。线性瓶颈指的是一个瓶颈层，它是一个带有1×1滤波器的卷积层，与线性激活函数相结合。因为传统的ReLU函数变换提供了具有信息丢失可能性的非线性，所以MobileNetV2转而将线性瓶颈层插入到卷积块中（假设特征流是低维且可捕获的）。</p>
<h3 id="c.-反向残差"><em>C. 反向残差</em></h3>
<p>​
作为一种更安全、更有效的方法来提取输入数据的所有必要信息，瓶颈层取代了ReLU层。在瓶颈块的开始处还有一个扩展层。此外，MobileNetV2直接在瓶颈之间使用捷径，以更好地跨多个层传播梯度，并防止梯度丢失和爆炸。反向残差块经过测试，其有效作用几乎与残差块相同，同时显著降低了内存开销。</p>
<h3 id="d.-网络架构搜索"><em>D. 网络架构搜索</em></h3>
<p>​
通过强化学习和递归神经网络（RNN），将网络架构搜索应用于MobileNetV3，以确定受限硬件平台的最优架构。它是一种为神经网络的体系结构构造搜索空间，并用强化</p>
<p>学习在分层搜索空间中高效搜索，以逼近特定任务模型的最佳结构的方法。例如，基于MobileNetV2的原始设计，将MobileNetV3的扩展层重新设计为图2。</p>
<p>​
由于RNN控制器和搜索空间的相似性，MobileNetV3使用MnasNet-A1作为初始模型。此外，对强化学习中的奖励设计进行了修改，以更好地适应小型移动模型。在层的类型固定后，使用NetAdapt（一种微调每层中超参数的方法）来优化模型。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304105920919.png"
alt="image-20220304105920919" /></p>
<h5 id="图2-原始末级和重新设计的末级的比较">图2
原始末级和重新设计的末级的比较。</h5>
<h3 id="e.-swish函数"><em>E. Swish函数</em></h3>
<p>​
为了获得更高的精度，引入了一种新的激活函数swish来代替ReLU函数。该函数定义为：
<span class="math display">\[
swish(x)=x⋅\sigma(x)
\]</span> ​
然而，swish公式中的sigmoid函数可能在移动设备上消耗大量的计算资源。为了解决这个问题，MobileNetv3的作者使用Relu6函数来近似Swish中的Sigmoid函数，并</p>
<p>产生Swish函数的近似，称为Swish的hard版本（H-Swish），定义为： <span
class="math display">\[
h-swish[x]=x\frac{ReLU6(x+3)}{6}
\]</span></p>
<h3 id="f.-实验中的额外模型"><em>F. 实验中的额外模型</em></h3>
<p>​
AlexNet是一个非常初始的深度CNN，开始使用ReLU非线性而不是tanh函数，并且可以放在多个GPU上。适用于高分辨率图像。然而，该模型的主要缺点是由于大量的参数而导致严重的过拟合问题。</p>
<p>​
InceptionV3首先将批处理归一化层应用于数据的传播，以加速梯度下降的过程。InceptionV3中的Inception模块经过优化，与InceptionV2相比具有更多分支。此外，在InceptionV3中实现了分解为小卷积的关键见解，这意味着将2维卷积核分离为两个1维卷积核。</p>
<p>​
ShuffleNet[15]使用组卷积和信道混洗来降低计算复杂度。通过深度方向可分离卷积层提取特征，在不显著降低精度的情况下，具有较低的计算量和较高的数据传播速度。</p>
<h2 id="iii.-实验">III. 实验</h2>
<h3 id="a.-数据集"><em>A. 数据集</em></h3>
<p>​
在本文中，我们使用了从Kaggle下载的三个不同的数据集。这些数据集将模拟MobileNetv3可应用于移动设备的日常场景。</p>
<p>​
如图3所示，在第一行中，第一个数据集是Fruit360数据集，包括131个水果类别和67692个训练图像。每个水果都是从不同的角度拍摄多次，并有一个清晰的背景。图3</p>
<p>中的第二行展示了第二个数据集，即10只猴子的1097个图像。第三个数据集包含16类鸟类和总共150张图像，如第三行所示。这个数据集很小而且不平衡，鸟类随机分布在不同的背景中。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304111031565.png"
alt="image-20220304111031565" /></p>
<h5
id="图3-样本来自三个实验数据集第一行是fruit360数据集第二行是猴子数据集第三行是鸟类数据集">图3
样本来自三个实验数据集。第一行是Fruit360数据集；第二行是猴子数据集；第三行是鸟类数据集。</h5>
<p>​
在数据预处理方面，我们对三个数据集进行了相同的操作：首先，将训练数据集随机拆分为训练子集和验证子集，拆分比例为0.7；其次，将除InceptionV3外的所有图像的大小调整为
224×224，并归一化为模型的输入。对于InceptionV3，输入图像的大小调整为299×299
。</p>
<h3 id="b.-实验步骤"><em>B.</em> <em>实验步骤</em></h3>
<p>​ 在本文中，我们比较了5个模型（MobileNetV3-Large，MobileNetV3-Small
， AlexNet，InceptionV3 和ShuffleNetV2）在3个不同数据集上的性能。</p>
<p>​ 这5个模型之间的FLOPs和参数数量的比较如表III所示。</p>
<table>
<colgroup>
<col style="width: 16%" />
<col style="width: 22%" />
<col style="width: 22%" />
<col style="width: 9%" />
<col style="width: 14%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="header">
<th>模型</th>
<th>MobileNetV3-Large</th>
<th>MobileNetV3-Small</th>
<th>AlexNet</th>
<th>InceptionV3</th>
<th>ShuffleNetV2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>FLOPs（百万）</td>
<td>226.0</td>
<td>29.65</td>
<td>714.7</td>
<td>5731</td>
<td>148.8</td>
</tr>
<tr class="even">
<td>参数（百万）</td>
<td>5.48</td>
<td>2.54</td>
<td>61.1</td>
<td>23.8</td>
<td>2.28</td>
</tr>
</tbody>
</table>
<p>​ 数据集包括与水果、鸟类和猴子相关的日常生活图像分类问题。</p>
<p>​
我们根据不同数据集的唯一分类类别的数量替换每个模型的最后一个分类层。使用了ImageNet[19]上预先训练的权重[17，18]。然后通过设置所有可训练的层来微调模型。</p>
<p>使用预先训练的权重进行训练使训练过程更简单，并导致更快的收敛。对模型进行微调是为了使模型适应特定的任务。在三个数据集上的实验步骤相同。</p>
<h3 id="c.-评估指标"><em>C. 评估指标</em></h3>
<h5 id="准确性"><em>1)</em> <em>准确性：</em></h5>
<p>​
为了评估模型在数据集上的性能，计算预测为正的样本（实际上是正的）的数量和预测为负的样本（实际上是负的）的数量。它反映了模型从整个数据集中区分真阳性样本和真阴性样本的精度。</p>
<p>​ 精度定义为： <span class="math display">\[
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}
\]</span> ​
其中TP、TN、FP、FN分别是真阳性、真阴性、假阳性和假阴性样本的数量。</p>
<h5 id="交叉熵损失"><em>2)</em> <em>交叉熵损失：</em></h5>
<p>​
在训练神经网络的阶段，我们通常定义一个目标函数，并将训练过程转化为一个优化问题。为了客观地衡量神经网络预测结果的波动程度，并在搜索空间中为我们提供一个合理的优化方向，本文在模型的训练阶段采用了交叉熵作为损失函数。</p>
<p>​ 交叉熵损失定义为： <span class="math display">\[
CrossEntropyLoss=\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M}{p(x_{ij})log(q(x_{ij}))}
\]</span> 其中N是训练集中的样本数量；M是训练集中的类的数目；<span
class="math inline">\(p(x_{ij})\)</span>是第i个样本属于第j类的真实概率；
<span
class="math inline">\(q(x_{ij})\)</span>是模型产生的第i个样本属于第j类的概率。</p>
<h5 id="roc曲线"><em>3)</em> <em>ROC曲线：</em></h5>
<p>​
为了直观地显示真阳性率（TPR）和假阳性率（FPR）之间的权衡，绘制了受试者工作特征（ROC）曲线，其中<span
class="math inline">\(TPR=TP/P\)</span>是模型正确标记的阳性样本的比例，以及<span
class="math inline">\(FPR=FP/N\)</span>是被错误标记为阳性的阴性样本的比例。</p>
<p>​
ROC曲线下的面积通常用于衡量模型的性能。图上的对角线表示随机标记样本的模型。比随机模型更好的模型应该出现在对角线上方。模型离随机越远（即，当ROC曲线下的面积远大于0.5时），模型越好。</p>
<h3 id="d.-实验结果"><em>D.</em> <em>实验结果</em></h3>
<h4 id="在水果数据集上的实验"><em>1)</em>
<em>在水果数据集上的实验：</em></h4>
<p>​
水果数据集包含来自131个水果类别的90483张图片。一类水果的所有训练和测试照片都是从该类别的单个水果代表的不同角度拍摄的，背景为白色。这意味着一个特定类别的训练和测试数据之间没有明显的差异。训练规模足够大，图像中的水果几乎没有任何背景干扰。也有大量的测试数据。因此，可以认为测试结果是令人信服的。</p>
<p>​
如表IV所示，与其他两个数据集上的实验相比，水果数据集的微调训练时间特别长。这可能是由于大数据集和复杂的水果品种。</p>
<h5
id="表iv-不同实验模型在水果数据集上的近似微调训练时间绝对时间高度依赖于训练环境而模型之间的时间比较相对有意义">表IV
不同实验模型在水果数据集上的近似微调训练时间。绝对时间高度依赖于训练环境，而模型之间的时间比较相对有意义。</h5>
<table>
<thead>
<tr class="header">
<th>模型</th>
<th>大致训练时间（分钟）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MobileNetV3-Large</td>
<td>40</td>
</tr>
<tr class="even">
<td>MobileNetV3-Small</td>
<td>33</td>
</tr>
<tr class="odd">
<td>AlexNet</td>
<td>417</td>
</tr>
<tr class="even">
<td>InceptionV3</td>
<td>225</td>
</tr>
<tr class="odd">
<td>ShuffleNetV2</td>
<td>42</td>
</tr>
</tbody>
</table>
<h5
id="image-20220304114026947图4-通过在水果数据集上的实验比较了整个微调训练过程中训练和验证的准确性和损失"><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304114026947.png"
alt="image-20220304114026947" />图4
通过在水果数据集上的实验，比较了整个微调训练过程中训练和验证的准确性和损失。</h5>
<p>​
虽然训练时间相对较长，但水果数据集实际所需的训练epoch数量较少，以实现水果数据集的良好性能。在图4中，所有的
MobileNetV3-Large 、 MobileNetV3-Small
、AlexNet和InceptionV3都可以从第一个epoch开始达到接近1的精度。在整个训练过程中，只有ShuffleNetV2模型表现出较低的验证精度。通过比较训练和验证评估，对于所有模型，验证精度甚至普遍高于训练精度。因此，在这些实验中不存在过拟合问题。</p>
<p>​
在Fruit数据集上对所有实验模型的测试精度和ROC曲线进行比较，得出了相同的结论：一方面，MobileNetV3-Large
的性能最好,其次是MobileNetV3-Small。InceptionV3具有类似但稍低的精度。尽管AlexNet在该数据集中排名第四，但其准确性仍然很高。另一方面，ShuffleNetV2的性能并不令人满意，测试精度为0.79，与其他模型相比，分类能力差距明显。图5还清楚地表明，所有模型的性能都比随机猜测的要好得多。<img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304114343095.png"
alt="image-20220304114343095" /></p>
<h5 id="图5-不同模型在水果数据集上的roc曲线比较">图5
不同模型在水果数据集上的ROC曲线比较。</h5>
<p>​
考虑到微调的训练时间、测试时间和数据集上所有模型的最终性能，ShuffleNetV2对应于高效率而低精度。AlexNet和InceptionV3可以以更高的时间和资源成本实现高精度。只有两个MobileNetV3型号在准确性和效率之间实现了预期的出色平衡。MobileNetV3不仅耗时最短，而且分类性能最好。</p>
<h4 id="在猴子数据集上的实验"><em>2)</em>
<em>在猴子数据集上的实验：</em></h4>
<p>​
猴子数据集由10种猴子的近1400张图片组成。由于移动设备拍摄的照片分辨率相对较低，而动物是移动设备经常捕捉的对象，因此我们选取该数据集来验证MobileNetV3在低分辨率动物图形分类中的性能。数据集中的每个图像都包含来自这十个物种之一的猴子。图像的背景是猴子生活的地方。猴子通常在照片的中央，背景很模糊。</p>
<p>​
在数据集的每一类中，图像的数量几乎相同。它可以帮助防止由于训练数据集的不平衡而导致的过拟合问题。此外，每个类中有近30张图片来验证训练的模型，客观地展示了每个模型的性能。每个类别的标签和图像数量如表V所示。</p>
<h5 id="表v-每类猴子数据集中的图像数量">表V
每类猴子数据集中的图像数量。</h5>
<table>
<thead>
<tr class="header">
<th>标签</th>
<th>训练图像</th>
<th>测试图像</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mantled howler</td>
<td>105</td>
<td>26</td>
</tr>
<tr class="even">
<td>Patas monkey</td>
<td>111</td>
<td>28</td>
</tr>
<tr class="odd">
<td>Bald uakari</td>
<td>110</td>
<td>27</td>
</tr>
<tr class="even">
<td>Japanese macaque</td>
<td>122</td>
<td>30</td>
</tr>
<tr class="odd">
<td>Pygmy marmoset</td>
<td>105</td>
<td>26</td>
</tr>
<tr class="even">
<td>White headed capuchin</td>
<td>113</td>
<td>28</td>
</tr>
<tr class="odd">
<td>Silvery marmoset</td>
<td>106</td>
<td>26</td>
</tr>
<tr class="even">
<td>Common squirrel monkey</td>
<td>114</td>
<td>28</td>
</tr>
<tr class="odd">
<td>Black-headed night monkey</td>
<td>106</td>
<td>27</td>
</tr>
<tr class="even">
<td>Nilgiri langur</td>
<td>106</td>
<td>26</td>
</tr>
</tbody>
</table>
<p>​
在实验中，训练图像被分为两部分：由770幅猴子图像组成的训练集和由328幅猴子图像组成的验证集。在训练阶段之前，所有的图片都被重新缩放到224×224像素，以适应大多数卷积神经网络的输入大小（除了InceptionV3的299×299像素）。在训练过程中，我们从ImageNet迁移学习中加载权重，并将其用作初始权重。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304115111033.png"
alt="image-20220304115111033" /></p>
<h6
id="图6-在猴子数据集实验的微调训练过程中训练和验证的准确性和损失的比较">图6
在猴子数据集实验的微调训练过程中，训练和验证的准确性和损失的比较。</h6>
<p>​
如图6所示，MobileNetV3-Large和MobileNetV3-Small都在4个时期内达到了收敛，甚至达到了与InceptionV3相同的高训练精度，InceptionV3是一个比MobileNTV3大得多的神经网络。与同样为移动设备设计的ShuffleNetV2相比，MobileNetV3在更少的时间内以更高的精度收敛，这表明MobileNetV3更容易在该猴子数据集和其他类似动物的低分辨率数据集中进行训练。</p>
<p>​
在测试阶段，将所有五个训练好的模型应用于测试集。每个模型的性能结果如图6所示。</p>
<p>​
在所有五种模型中，MobileNetV3-Large的测试精度最高，其次是MobileNetV3-Small。图7说明了相同的结果。实验结果表明，MobileNetV3能够很好地提取低分辨率图</p>
<p>像的特征，并应用于图像分类。根据大量的触发器和参数（如表3所示），InceptionV3应该具有最好的泛化能力。然而，它的表现并不如预期。我们假设原因在于猴子数据集的训练规模太小，以至于如此大的模型无法达到其最佳性能，这也表明MobileNetV3可以使用小数据集进行训练并达到较高的精度。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304115244692.png"
alt="image-20220304115244692" /></p>
<h5 id="图7-猴子数据集上不同模型的roc曲线比较">图7
猴子数据集上不同模型的ROC曲线比较。</h5>
<p>​
为了测试每个模型的效率，我们记录了所有五个模型预测测试集中所有标签的时间。结果和分析与其他两个数据集一起显示在第三章D.4图10中。</p>
<h4 id="在bird数据集上的实验"><em>3)</em>
<em>在Bird数据集上的实验：</em></h4>
<p>​
由于Bird数据集只包含150幅图像，并且每个类别的图像不到10幅，因此很难对其进行训练，并且很容易变得过拟合。在整个大图像中，不同的背景和小鸟的大小使得在这个数据集上的实验更难达到好的结果。与其他两个数据集相比，Bird数据集由于规模最小，所需的训练时间最少。</p>
<h6
id="表vi-不同实验模型的bird数据集的微调训练时间绝对时间几乎相同在训练期间记录最佳验证准确度">表VI
不同实验模型的Bird数据集的微调训练时间。绝对时间几乎相同。在训练期间记录最佳验证准确度。</h6>
<table>
<thead>
<tr class="header">
<th>模型</th>
<th>训练时间</th>
<th>最佳验证准确度</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MobileNetV3-Large</td>
<td>14min 1s</td>
<td><strong>0.80</strong></td>
</tr>
<tr class="even">
<td>MobileNetV3-Small</td>
<td>14min 18s</td>
<td>0.78</td>
</tr>
<tr class="odd">
<td>AlexNet</td>
<td>14min 13s</td>
<td>0.60</td>
</tr>
<tr class="even">
<td>InceptionV3</td>
<td>14min 26s</td>
<td>0.67</td>
</tr>
<tr class="odd">
<td>ShuffleNetV2</td>
<td>14min 6s</td>
<td>0.60</td>
</tr>
</tbody>
</table>
<p>​
如表VI所示，所有模型的训练时间几乎相同。这表明时间可能不是一个好的比较指标，因为鸟类数据集的模型之间的时间差距不像水果数据集的模型之间的时间差距那么显著。然而，在与其他两个数据集相同的训练时间内，MobileNetV3-Large和MobileNetV3-Small仍然获得了比其他模型高得多的验证精度。实验过程中更多的精度和损耗细节如图8所示。</p>
<p>​
图8表明，所有模型在Bird数据集上都表现出不同程度的过拟合。这主要是由于每个类别的训练数据不平衡，以及Bird数据集中的数据数量较少。根据图8（B）中的训练损失趋势，除ShuffleNetV2外，所有模型在训练过程中都达到了良好的收敛。验证损失的图8（d）显示AlexNet在此分类任务中失败。此外，AlexNet、InceptionV3和ShuffleNetV2在10个训练时期后遇到了严重的过拟合。MobileNetv3-Large和MobileNetv3-Small收敛速度更快且较少过拟合。这两个模型的验证精度普遍高于其他模型。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304115908752.png"
alt="image-20220304115908752" /></p>
<h5
id="图8-在bird数据集实验上比较了整个微调训练过程中训练和验证的准确性和损失">图8
在Bird数据集实验上，比较了整个微调训练过程中训练和验证的准确性和损失。</h5>
<p>​
图9还表明，MobileNetv3-Large在所有模型中实现了最佳性能。通过ROC曲线下面积测量，MobileNetV3-Small具有几乎相同的优异性能。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304115954345.png"
alt="image-20220304115954345" /></p>
<h4 id="整体测试性能对比"><em>4)</em> <em>整体测试性能对比：</em></h4>
<p>​
从上述对单个数据集的实验分析中可以发现，在训练过程中，MobileNetV3-Large总是能够在所有实验模型中获得最好的性能。MobileNetv3-Small通常是第二个。此外，MobileNetV3的训练时间明显短于其他模型。</p>
<p>​ 我们希望在测试性能上再次验证上述培训过程结果（第III章
D.1至第III章D.3。为此，在所有五个模型的三个数据集的测试数据上进行了实验。图10（a）和（b）分别展示了关于效率和准确性的测试总结。</p>
<p>​
如图10（b）所示，MobileNetv3的两个模型对所选数据集都保持了最高的分类精度。MobileNetv3-Large的表现略好于MobileNetv3-Small。</p>
<p>​
除了分类精度，我们还关注模型效率。图10（a）表明，与其他实验模型相比，MobileNetV3的测试时间并没有明显延长。</p>
<p><img
src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304120220511.png"
alt="image-20220304120220511" /></p>
<h6
id="图10a三个不同数据集上所有实验模型的测试时间比较由于三个数据集的原始测试规模差异较大我们将所有测试时间除以相应数据集的测试次数b在三个不同数据集上比较所有实验模型的测试精度">图10（a）三个不同数据集上所有实验模型的测试时间比较。由于三个数据集的原始测试规模差异较大，我们将所有测试时间除以相应数据集的测试次数。（b）在三个不同数据集上比较所有实验模型的测试精度。</h6>
<p>​ 从所有模型的训练和测试过程中的精度和效率分析可以看出
，两个MobileNetV3模型比大型CNN模型（如InceptionV3和AlexNet）所需的时间要短得多（尤其是微调训练
时间
），同时达到了令人满意的精度.MobileNetV3的效率也比其他为移动终端设计的网络（如ShuffleNetV2）略高，但性能要好得多。</p>
<p>​
总的来说，我们的实验结果验证了MobileNetV3可以用少量的时间资源达到高精度，这意味着它非常适合于计算资源有限、需要高效率的移动设备。</p>
<h4 id="关于合适数据集的特征的猜想"><em>5)</em>
<em>关于合适数据集的特征的猜想：</em></h4>
<p>​
作为实验结果分析的进一步，我们通过比较MobileNetv3对三个不同的数据集进行分类的性能，得出了关于哪种数据集更适合于MobileNetV3的一些猜想.</p>
<p>从图10（b）和单个数据集的ROC曲线（即图5、7和9）可以发现，Fruit-360数据集在极短的时间内导致1.0的准确度，而Monkey数据集在几个微调训练时期后对应于相当好的准确度（高于0.95）。然而，与其他两个数据集相比，Bird数据集的精度要低得多（低于0.50）。</p>
<p>​
考虑到这些数据集的特点，水果数据集是日常生活对象图像的代表，在大量不同类别之间没有显著差异。每个类别的训练集足够大，并且没有背景干扰。猴子数据集由仅来自十个类别的猴子的低分辨率动物图像组成。需要分类的猴子被放在图像的中心。图像背景是猴子通常生活的环境，但它们是模糊的。鸟类数据集只有十类鸟类的少量图像。虽然这些图像的分辨率很高，但图像背景杂乱，需要分类的鸟类在整个图像中的尺寸很小。</p>
<p>​ 因此，我们假设适用于MobileNetV3分类任务的图像数据集的特征如下：</p>
<ul>
<li><p>分类对象在没有强背景干扰的图像中被突出显示。</p></li>
<li><p>图像没有高分辨率要求（即，对低分辨率图像友好）。</p></li>
<li><p>对于已分类的类别，训练数据集在相对较大的规模上更好，这意味着已分类的对象在训练库中更常见。</p></li>
<li><p>被分类的对象处于其类别的典型形状或状态，并且背景最好也是常见的。</p></li>
<li><p>没有必要在数据集中的不同类别之间有明显的差异，因为CNN可以比人类的眼睛更精确地捕捉特征。</p>
<p>对MobileNetV3合适数据集的特性的实验总结表明，MobileNetV3是专为移动设备设计的，能够在极短的时间内处理日常生活照片的分类任务。</p></li>
</ul>
<h2 id="iv.-结论">IV. 结论</h2>
<p>​
本文基于通常由移动设备捕获和处理的图像数据集，比较了MobileNetV3和某些标准CNN模型的图像分类任务的性能。通过对实验结果的比较和分析，我们发现MobileNetV3模型能够以更高的效率完成图像分类任务。同时，它们的最终精度明显高于其他模型的精度。此外，我们注意到，MobileNetV3适用于包含具有较少背景干扰的日常生活对象的图像，即使图像是低分辨率的。因此，MobileNetV3可以非常方便地处理移动终端的图像分类任务。</p>
<p>​
作为我们研究的进一步工作，我们想要总结其他大型CNN的优势，这些优势可以用来进一步更好地调整MobileNetV3模型，以提高其性能，同时避免架构扩展。我们还计划使用MobileNetV3模型在更多的图像数据集上进行实验，旨在总结和确认在MobileNetV3上表现出色的图像的更普遍特征。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">图像分类</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/123r/pic-bed/raw/master/img/image-20220304130605359.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechatment.jpg" target="_blank"><img class="post-qr-code-img" src="/images/wechatment.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/images/alipayment.jpg" target="_blank"><img class="post-qr-code-img" src="/images/alipayment.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/05/13/%E6%96%B9%E8%88%9F%EF%BC%9A%E7%94%9F%E5%AD%98%E8%BF%9B%E5%8C%96-%E6%81%90%E9%BE%99%E5%9F%B9%E8%82%B2%E6%96%B9%E6%B3%95/"><img class="prev-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">方舟：生存进化 恐龙培育方法</div></div></a></div><div class="next-post pull-right"><a href="/2022/03/09/%E5%A4%A7%E6%B0%94%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B-%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89/"><img class="next-cover" src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220309171008482.png" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大气散射模型-图像去雾基础知识（一）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2019/12/20/Hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%92%8CHexo%E4%B8%8B%E7%9A%84Markdown%E8%AF%AD%E6%B3%95-GFM/" title="Hexo常用命令和Hexo下的Markdown语法(GFM)"><img class="cover" src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220308143527169.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-12-20</div><div class="title">Hexo常用命令和Hexo下的Markdown语法(GFM)</div></div></a></div><div><a href="/2020/02/18/win10-deepin%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/" title="win10+deepin双系统安装"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-18</div><div class="title">win10+deepin双系统安装</div></div></a></div><div><a href="/2022/03/09/%E5%A4%A7%E6%B0%94%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B-%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89/" title="大气散射模型-图像去雾基础知识（一）"><img class="cover" src="https://gitee.com/123r/pic-bed/raw/master/img/image-20220309171008482.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-09</div><div class="title">大气散射模型-图像去雾基础知识（一）</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/avatar.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png'" alt="avatar"/></div><div class="author-info__name">何佩奇</div><div class="author-info__description">与其感慨路难行，不如马上出发。</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Shunder" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://www.weibo.com/u/2631763173" target="_blank" title="新浪微博"><i class="fa-brands fa-weibo"></i></a><a class="social-icon" href="mailto:peijinhe@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/6758177/" target="_blank" title="哔哩哔哩"><i class="fa-brands fa-bilibili"></i></a><a class="social-icon" href="https://twitter.com/Pigeon520" target="_blank" title="twitter"><i class="fa-brands fa-twitter"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS订阅"><i class="fa-solid fa-square-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">🍭欢迎你的来访<br>🍭听说留言的人会有好运哦！</div></div><div class="card-widget hitokoto" id="hitokoto"><div class="item-headline"><i class="fa-fw fa-fw fa fa-book"></i><span>一言</span></div><div class="item-content"><script src="https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js"></script><script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js"></script><script src="https://cdn.jsdelivr.net/gh/shunder/shunder.github.io@master/lib/hitokoto.js"></script></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84mobilenetv3%E7%AE%97%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">用于图像分类的MobileNetV3算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AF%8D-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87mobilenetv3"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">关键词-卷积神经网络；图像分类；移动设备；MobileNetV3</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#i.-%E7%BB%AA%E8%AE%BA"><span class="toc-number">1.2.</span> <span class="toc-text">I. 绪论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ii.-%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">II. 模型的架构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8%E4%B8%80-mobilenetv3-large%E7%9A%84%E8%A7%84%E6%A0%BCexpand%E8%A1%A8%E7%A4%BA%E7%A4%BA%E7%94%A8%E4%BA%8E%E4%BB%8E%E5%B1%82%E7%9A%84%E8%BE%93%E5%85%A5%E6%89%A9%E5%B1%95%E7%89%B9%E5%BE%81%E7%A9%BA%E9%97%B4%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%BB%A4%E6%B3%A2%E5%99%A8%E7%9A%84%E6%95%B0%E9%87%8Fse%E6%8C%87%E7%A4%BA%E5%9C%A8%E8%AF%A5%E5%9D%97%E4%B8%AD%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E6%8C%A4%E5%8E%8B%E5%92%8C%E6%BF%80%E5%8A%B1nl%E8%A1%A8%E7%A4%BA%E8%AF%A5%E5%9D%97%E7%9A%84%E9%9D%9E%E7%BA%BF%E6%80%A7%E7%B1%BB%E5%9E%8Bbn%E8%A1%A8%E7%A4%BA%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">1.3.0.0.1.</span> <span class="toc-text">表一
MobileNetv3-Large的规格。#expand表示示用于从层的输入扩展特征空间的卷积滤波器的数量。SE指示在该块中是否存在挤压和激励。NL表示该块的非线性类型。BN表示批标准化。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%BE1-mobilenetv3%E6%9E%B6%E6%9E%84mobilenetv3-large%E5%92%8Cmobilenetv3-small%E7%9A%84%E9%80%9A%E7%94%A8%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%90%8C"><span class="toc-number">1.3.0.0.2.</span> <span class="toc-text">图1
MobileNetV3架构。MobileNetv3-Large和MobileNetv3-Small的通用架构相同。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8ii-mobilenetv3-small%E8%A7%84%E6%A0%BC%E6%89%80%E6%9C%89%E7%AC%A6%E5%8F%B7%E4%B8%8E%E8%A1%A8i%E7%9B%B8%E5%90%8C"><span class="toc-number">1.3.0.0.3.</span> <span class="toc-text">表II
MobileNetV3-Small规格。所有符号与表I相同。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#a.-%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.3.1.</span> <span class="toc-text">A. 深度可分离卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#b.-%E7%BA%BF%E6%80%A7%E7%93%B6%E9%A2%88"><span class="toc-number">1.3.2.</span> <span class="toc-text">B. 线性瓶颈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#c.-%E5%8F%8D%E5%90%91%E6%AE%8B%E5%B7%AE"><span class="toc-number">1.3.3.</span> <span class="toc-text">C. 反向残差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#d.-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2"><span class="toc-number">1.3.4.</span> <span class="toc-text">D. 网络架构搜索</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%BE2-%E5%8E%9F%E5%A7%8B%E6%9C%AB%E7%BA%A7%E5%92%8C%E9%87%8D%E6%96%B0%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%9C%AB%E7%BA%A7%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">1.3.4.0.1.</span> <span class="toc-text">图2
原始末级和重新设计的末级的比较。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#e.-swish%E5%87%BD%E6%95%B0"><span class="toc-number">1.3.5.</span> <span class="toc-text">E. Swish函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#f.-%E5%AE%9E%E9%AA%8C%E4%B8%AD%E7%9A%84%E9%A2%9D%E5%A4%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.6.</span> <span class="toc-text">F. 实验中的额外模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#iii.-%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.4.</span> <span class="toc-text">III. 实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#a.-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.4.1.</span> <span class="toc-text">A. 数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%BE3-%E6%A0%B7%E6%9C%AC%E6%9D%A5%E8%87%AA%E4%B8%89%E4%B8%AA%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AC%AC%E4%B8%80%E8%A1%8C%E6%98%AFfruit360%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AC%AC%E4%BA%8C%E8%A1%8C%E6%98%AF%E7%8C%B4%E5%AD%90%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AC%AC%E4%B8%89%E8%A1%8C%E6%98%AF%E9%B8%9F%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.4.1.0.1.</span> <span class="toc-text">图3
样本来自三个实验数据集。第一行是Fruit360数据集；第二行是猴子数据集；第三行是鸟类数据集。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#b.-%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.4.2.</span> <span class="toc-text">B. 实验步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#c.-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">1.4.3.</span> <span class="toc-text">C. 评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%87%86%E7%A1%AE%E6%80%A7"><span class="toc-number">1.4.3.0.1.</span> <span class="toc-text">1) 准确性：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.4.3.0.2.</span> <span class="toc-text">2) 交叉熵损失：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#roc%E6%9B%B2%E7%BA%BF"><span class="toc-number">1.4.3.0.3.</span> <span class="toc-text">3) ROC曲线：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#d.-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">1.4.4.</span> <span class="toc-text">D. 实验结果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">1)
在水果数据集上的实验：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8iv-%E4%B8%8D%E5%90%8C%E5%AE%9E%E9%AA%8C%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%97%B6%E9%97%B4%E7%BB%9D%E5%AF%B9%E6%97%B6%E9%97%B4%E9%AB%98%E5%BA%A6%E4%BE%9D%E8%B5%96%E4%BA%8E%E8%AE%AD%E7%BB%83%E7%8E%AF%E5%A2%83%E8%80%8C%E6%A8%A1%E5%9E%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E6%97%B6%E9%97%B4%E6%AF%94%E8%BE%83%E7%9B%B8%E5%AF%B9%E6%9C%89%E6%84%8F%E4%B9%89"><span class="toc-number">1.4.4.1.1.</span> <span class="toc-text">表IV
不同实验模型在水果数据集上的近似微调训练时间。绝对时间高度依赖于训练环境，而模型之间的时间比较相对有意义。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#image-20220304114026947%E5%9B%BE4-%E9%80%9A%E8%BF%87%E5%9C%A8%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%AF%94%E8%BE%83%E4%BA%86%E6%95%B4%E4%B8%AA%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%AE%AD%E7%BB%83%E5%92%8C%E9%AA%8C%E8%AF%81%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E5%92%8C%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.4.4.1.2.</span> <span class="toc-text">图4
通过在水果数据集上的实验，比较了整个微调训练过程中训练和验证的准确性和损失。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%BE5-%E4%B8%8D%E5%90%8C%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84roc%E6%9B%B2%E7%BA%BF%E6%AF%94%E8%BE%83"><span class="toc-number">1.4.4.1.3.</span> <span class="toc-text">图5
不同模型在水果数据集上的ROC曲线比较。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E7%8C%B4%E5%AD%90%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">2)
在猴子数据集上的实验：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8v-%E6%AF%8F%E7%B1%BB%E7%8C%B4%E5%AD%90%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E6%95%B0%E9%87%8F"><span class="toc-number">1.4.4.2.1.</span> <span class="toc-text">表V
每类猴子数据集中的图像数量。</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9B%BE6-%E5%9C%A8%E7%8C%B4%E5%AD%90%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9E%E9%AA%8C%E7%9A%84%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%AE%AD%E7%BB%83%E5%92%8C%E9%AA%8C%E8%AF%81%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E5%92%8C%E6%8D%9F%E5%A4%B1%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">1.4.4.2.1.1.</span> <span class="toc-text">图6
在猴子数据集实验的微调训练过程中，训练和验证的准确性和损失的比较。</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%BE7-%E7%8C%B4%E5%AD%90%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E4%B8%8D%E5%90%8C%E6%A8%A1%E5%9E%8B%E7%9A%84roc%E6%9B%B2%E7%BA%BF%E6%AF%94%E8%BE%83"><span class="toc-number">1.4.4.2.2.</span> <span class="toc-text">图7
猴子数据集上不同模型的ROC曲线比较。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8bird%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">3)
在Bird数据集上的实验：</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%A1%A8vi-%E4%B8%8D%E5%90%8C%E5%AE%9E%E9%AA%8C%E6%A8%A1%E5%9E%8B%E7%9A%84bird%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%97%B6%E9%97%B4%E7%BB%9D%E5%AF%B9%E6%97%B6%E9%97%B4%E5%87%A0%E4%B9%8E%E7%9B%B8%E5%90%8C%E5%9C%A8%E8%AE%AD%E7%BB%83%E6%9C%9F%E9%97%B4%E8%AE%B0%E5%BD%95%E6%9C%80%E4%BD%B3%E9%AA%8C%E8%AF%81%E5%87%86%E7%A1%AE%E5%BA%A6"><span class="toc-number">1.4.4.3.0.1.</span> <span class="toc-text">表VI
不同实验模型的Bird数据集的微调训练时间。绝对时间几乎相同。在训练期间记录最佳验证准确度。</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%BE8-%E5%9C%A8bird%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9E%E9%AA%8C%E4%B8%8A%E6%AF%94%E8%BE%83%E4%BA%86%E6%95%B4%E4%B8%AA%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%AE%AD%E7%BB%83%E5%92%8C%E9%AA%8C%E8%AF%81%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E5%92%8C%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.4.4.3.1.</span> <span class="toc-text">图8
在Bird数据集实验上，比较了整个微调训练过程中训练和验证的准确性和损失。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%B5%8B%E8%AF%95%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.4.4.</span> <span class="toc-text">4) 整体测试性能对比：</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9B%BE10a%E4%B8%89%E4%B8%AA%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E6%89%80%E6%9C%89%E5%AE%9E%E9%AA%8C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B5%8B%E8%AF%95%E6%97%B6%E9%97%B4%E6%AF%94%E8%BE%83%E7%94%B1%E4%BA%8E%E4%B8%89%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%8E%9F%E5%A7%8B%E6%B5%8B%E8%AF%95%E8%A7%84%E6%A8%A1%E5%B7%AE%E5%BC%82%E8%BE%83%E5%A4%A7%E6%88%91%E4%BB%AC%E5%B0%86%E6%89%80%E6%9C%89%E6%B5%8B%E8%AF%95%E6%97%B6%E9%97%B4%E9%99%A4%E4%BB%A5%E7%9B%B8%E5%BA%94%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%B5%8B%E8%AF%95%E6%AC%A1%E6%95%B0b%E5%9C%A8%E4%B8%89%E4%B8%AA%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E6%AF%94%E8%BE%83%E6%89%80%E6%9C%89%E5%AE%9E%E9%AA%8C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B5%8B%E8%AF%95%E7%B2%BE%E5%BA%A6"><span class="toc-number">1.4.4.4.0.1.</span> <span class="toc-text">图10（a）三个不同数据集上所有实验模型的测试时间比较。由于三个数据集的原始测试规模差异较大，我们将所有测试时间除以相应数据集的测试次数。（b）在三个不同数据集上比较所有实验模型的测试精度。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%90%88%E9%80%82%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%89%B9%E5%BE%81%E7%9A%84%E7%8C%9C%E6%83%B3"><span class="toc-number">1.4.4.5.</span> <span class="toc-text">5)
关于合适数据集的特征的猜想：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#iv.-%E7%BB%93%E8%AE%BA"><span class="toc-number">1.5.</span> <span class="toc-text">IV. 结论</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/03/09/%E5%A4%A7%E6%B0%94%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B-%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89/" title="大气散射模型-图像去雾基础知识（一）">大气散射模型-图像去雾基础知识（一）</a><time datetime="2022-03-09T08:40:54.000Z" title="发表于 2022-03-09 16:40:54">2022-03-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/03/04/%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84MobileNetV3%E7%AE%97%E6%B3%95/" title="用于图像分类的MobileNetV3算法">用于图像分类的MobileNetV3算法</a><time datetime="2022-03-04T04:54:47.000Z" title="发表于 2022-03-04 12:54:47">2022-03-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2020/05/13/%E6%96%B9%E8%88%9F%EF%BC%9A%E7%94%9F%E5%AD%98%E8%BF%9B%E5%8C%96-%E6%81%90%E9%BE%99%E5%9F%B9%E8%82%B2%E6%96%B9%E6%B3%95/" title="方舟：生存进化 恐龙培育方法">方舟：生存进化 恐龙培育方法</a><time datetime="2020-05-13T12:30:28.000Z" title="发表于 2020-05-13 20:30:28">2020-05-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2020/02/18/win10-deepin%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/" title="win10+deepin双系统安装">win10+deepin双系统安装</a><time datetime="2020-02-18T07:16:01.000Z" title="发表于 2020-02-18 15:16:01">2020-02-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2019/12/21/%E7%BB%99%E5%8D%9A%E4%B8%BB%E5%85%85%E7%94%B5/" title="给博主充电">给博主充电</a><time datetime="2019-12-21T13:59:29.000Z" title="发表于 2019-12-21 21:59:29">2019-12-21</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2022 By 何佩奇</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="https://icp.gov.moe/?keyword=20221756" target="_blank">萌ICP备20221756号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '8LKcIz0qIdWfPvYx35gjp43p-gzGzoHsz',
      appKey: 'xcT3EN5azM7u7WN6p7GzyrPR',
      avatar: 'wavatar',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script>((window.gitter = {}).chat = {}).options = {
  disableDefaultChat: true,
};
document.addEventListener('gitter-sidecar-ready', (e) => {
  const GitterChat = e.detail.Chat
  let chat

  function initGitter () {
    chat = new GitterChat({
      room: 'imhpj/community',
      activationElement: '#chat_btn'
    });
  }

  initGitter()

  if (false) {
    document.addEventListener('pjax:complete', () => {
      chat.destroy()
      initGitter()
    })
  }

})</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async="async" defer="defer"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>